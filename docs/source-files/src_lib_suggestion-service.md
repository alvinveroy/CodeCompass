# `src/lib/suggestion-service.ts`

## Overview

The `src/lib/suggestion-service.ts` module provides the `SuggestionPlanner` class. This class is responsible for interacting with an LLM provider to generate a high-level plan and a summary for a given user query. It's designed to be a first step in an agentic workflow, where the plan and summary can guide further actions or be presented directly to the user.

## Key Classes and Methods

### `SuggestionPlanner` Class

-   **Purpose**: Orchestrates the generation of a plan and summary from an LLM based on a user's query.
-   **Constructor**:
    -   `constructor(llmProvider: LLMProvider)`: Takes an instance of an `LLMProvider` (defined in `src/lib/llm-provider.ts`) which will be used to communicate with the language model.

#### `public async initiateAgentQuery(prompt: string, sessionId?: string): Promise<AgentInitialQueryResponse>`

-   **Purpose**: Takes a user prompt and an optional session ID, then queries the LLM to produce both a step-by-step plan and a comprehensive summary for addressing the prompt.
-   **Parameters**:
    -   `prompt: string`: The user's query or task description.
    -   `sessionId?: string` (optional): An existing session ID. If not provided, a new UUID will be generated.
-   **Returns**: `Promise<AgentInitialQueryResponse>` - An object containing:
    -   `sessionId: string`: The session ID (either passed in or newly generated).
    -   `status: "COMPLETED" | "ERROR"`: Indicates the outcome of the operation.
    -   `message: string`: A human-readable message about the outcome.
    -   `generatedPlanText?: string`: The textual plan generated by the LLM.
    -   `agentState: AgentState`: The state of the agent after this operation.
        -   `sessionId`: Matches the returned `sessionId`.
        -   `query`: The original user `prompt`.
        -   `planText`: The `generatedPlanText`.
        -   `steps`: An empty array (as this method only plans, not executes).
        -   `context`: An empty array.
        -   `finalResponse`: The summary generated by the LLM.
        -   `isComplete`: `true` if the operation finished (even if with an error).
-   **Process**:
    1.  Resolves the `sessionId`.
    2.  Initializes an `AgentState` object.
    3.  Constructs a `fullPrompt` for the LLM, instructing it to generate two distinct sections: "PLAN" and "SUMMARY" based on the user's `prompt`. The prompt includes an example of the expected output format.
    4.  Calls `this.llmProvider.generateText(fullPrompt)` to get the LLM's response.
    5.  Parses the LLM's response to extract the text under "PLAN:" and "SUMMARY:".
        -   If parsing is successful, `agentState.planText` and `agentState.finalResponse` (summary) are populated.
        -   If parsing fails, `agentState.planText` is set to an error message, and the entire LLM response is used as the `agentState.finalResponse` (summary).
    6.  Sets `agentState.isComplete` to `true`.
    7.  Returns the `AgentInitialQueryResponse` object.
-   **Error Handling**:
    -   If an error occurs during LLM interaction, it's caught, and the `AgentInitialQueryResponse` will have a status of "ERROR".
    -   `agentState.planText` and `agentState.finalResponse` will contain error messages.

## Dependencies

-   `uuid`: For generating unique session IDs if one is not provided.
-   `./llm-provider`: For the `LLMProvider` interface and its implementations.
-   `./config-service`: For the `logger`.
-   `./types`: For `AgentInitialQueryResponse` and `AgentState` type definitions.

## Notes

-   The `SuggestionPlanner` currently focuses only on the initial planning and summarization phase. It does not execute the generated plan.
-   The `evaluateSuggestionInternal` and `executeNextAgentStep` methods, which might have been part of a previous design for plan execution, have been removed.
-   The quality of the plan and summary heavily depends on the capabilities of the underlying LLM provider and the clarity of the user's prompt.
